{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What is Text Summarization?\n",
        "\n",
        "Text summarization is the process of generating a shorter version of a text that preserves its main meaning, key ideas, and intent.\n",
        "\n",
        "It‚Äôs a form of text generation, where the model takes a long input (like an article, report, or paragraph) and generates a concise summary, just like a human would do."
      ],
      "metadata": {
        "id": "Inpe0KodDqJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two Main Types of Text Summarization\n",
        "1. Extractive Summarization\n",
        "\n",
        "The model selects important sentences or phrases directly from the original text.\n",
        "\n",
        "It does not generate new sentences; it simply extracts and rearranges existing content.\n",
        "\n",
        "Example:\n",
        "Input:\n",
        "\n",
        "\"The Indian Space Research Organisation (ISRO) launched the Chandrayaan-3 mission to explore the Moon's south pole. The mission aims to demonstrate safe landing and roving on the lunar surface.\"\n",
        "Extractive summary:\n",
        "\"ISRO launched Chandrayaan-3 to explore the Moon's south pole.\""
      ],
      "metadata": {
        "id": "tESaZ31JEBaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Abstractive Summarization\n",
        "\n",
        "The model understands the text and generates new sentences that express the same meaning ‚Äî like how humans paraphrase.\n",
        "\n",
        "It‚Äôs a truly generative approach.\n",
        "\n",
        "Example:\n",
        "Input:\n",
        "\n",
        "\"The Indian Space Research Organisation (ISRO) launched the Chandrayaan-3 mission to explore the Moon's south pole. The mission aims to demonstrate safe landing and roving on the lunar surface.\"\n",
        "Abstractive summary:\n",
        "\"ISRO‚Äôs Chandrayaan-3 mission targets a soft landing on the Moon‚Äôs south pole.\"\n",
        "\n",
        "üß© Common models:\n",
        "\n",
        "Transformer-based models like T5, BART, PEGASUS, GPT, LLaMA, etc."
      ],
      "metadata": {
        "id": "V92qDkXUEM6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚öôÔ∏è How It Works in Generative AI\n",
        "\n",
        "Generative AI models (like GPT, BART, T5) are trained on large datasets of (document, summary) pairs.\n",
        "\n",
        "Input: A long text.\n",
        "\n",
        "Encoder: Understands the meaning of the input text.\n",
        "\n",
        "Decoder: Generates a shorter version that preserves meaning.\n",
        "\n",
        "Training objective: Minimize the difference between generated summary and reference summary."
      ],
      "metadata": {
        "id": "HYVG9f8OEaPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applications of Text Summarization\n",
        "\n",
        "News summarization ‚Äì Summarizing news articles.\n",
        "\n",
        "Research summarization ‚Äì Summarizing scientific papers or abstracts.\n",
        "\n",
        "Legal/medical summarization ‚Äì Condensing long legal documents or patient histories.\n",
        "\n",
        "Customer service ‚Äì Summarizing support tickets or chat transcripts.\n",
        "\n",
        "Meeting summarization ‚Äì Summarizing transcripts from meetings or lectures."
      ],
      "metadata": {
        "id": "qsXMTid9EjXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "text = \"\"\"The global shift toward renewable energy is accelerating,\n",
        "driven by concerns over climate change and energy security. Solar\n",
        "and wind power installations have reached record levels worldwide.\"\"\"\n",
        "\n",
        "summary = summarizer(text, max_length=30, min_length=10, do_sample=False)\n",
        "print(summary[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTCSqh0eDxxX",
        "outputId": "b1742961-754c-4e43-c652-0d2c3449ac04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'summary_text': 'Solar and wind power installations have reached record levels worldwide. The global shift toward renewable energy is accelerating.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO7p7lJJDis1"
      },
      "outputs": [],
      "source": [
        "#from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line imports the pipeline function from the Hugging Face Transformers library.\n",
        "\n",
        "The Transformers library provides pre-trained models for:\n",
        "\n",
        "Text summarization\n",
        "\n",
        "Text classification\n",
        "\n",
        "Sentiment analysis\n",
        "\n",
        "Translation\n",
        "\n",
        "Image classification\n",
        "\n",
        "Question answering\n",
        "\n",
        "Text generation (GPT-like models)\n",
        "\n",
        "Many more‚Ä¶\n",
        "\n",
        "The pipeline function is a shortcut tool that makes it very easy to use pre-trained models without needing to write complex code.\n",
        "\n",
        "‚úÖ Why use pipeline?\n",
        "\n",
        "Because it:\n",
        "\n",
        "‚úî Loads a pre-trained model automatically\n",
        "\n",
        "You don‚Äôt need to manually load the tokenizer and model.\n",
        "\n",
        "‚úî Automatically handles tokenization\n",
        "\n",
        "It converts your text to tokens internally.\n",
        "\n",
        "‚úî Runs the model\n",
        "\n",
        "\n",
        "\n",
        "‚úî Returns clean, human-readable output\n",
        "\n"
      ],
      "metadata": {
        "id": "CUmwgdxeNlYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "do_sample=False\n",
        "\n",
        "This disables sampling and uses greedy decoding.\n",
        "\n",
        "üîç What is greedy decoding?\n",
        "\n",
        "The model picks the highest-probability next word at each step.\n",
        "\n",
        "Output is deterministic ‚Üí same input ‚Üí same summary every time.\n",
        "\n",
        "No randomness.\n",
        "\n",
        "If you set do_sample=True, the model would generate more diverse and creative summaries (but may vary each time)."
      ],
      "metadata": {
        "id": "Hhf7ONN32zJw"
      }
    }
  ]
}